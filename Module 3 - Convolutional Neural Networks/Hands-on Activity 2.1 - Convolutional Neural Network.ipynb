{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historic-trainer",
   "metadata": {},
   "source": [
    "# Activity 2.1 : Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b83ba8",
   "metadata": {},
   "source": [
    "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
    "--- | ---\n",
    "Course Code: | CPE 313\n",
    "Code Title: | Advanced Machine Learning and Deep Learning\n",
    "2nd Semester | AY 2025-2026\n",
    "  |  \n",
    "<u>**Hands-on Activity 3.1** | Convolutional Neural Network\n",
    "**Name** | Corpuz, Micki Laurren B.\n",
    "**Section** | CPE32S3\n",
    "**Date Performed**: | 08 February 2026\n",
    "**Date Submitted**: | 08 February 2026\n",
    "**Instructor**: | Engr. Neal Barton James Matira\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-manner",
   "metadata": {},
   "source": [
    "#### Objective(s):\n",
    "\n",
    "This activity aims to introduce how to build a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-transport",
   "metadata": {},
   "source": [
    "#### Intended Learning Outcomes (ILOs):\n",
    "* Demonstrate how to build and train convolutional neural network \n",
    "* Evaluate the accuracy and loss of the model using convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-providence",
   "metadata": {},
   "source": [
    "#### Resources:\n",
    "* Jupyter Notebook\n",
    "* CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-trail",
   "metadata": {},
   "source": [
    "#### Procedures\n",
    "Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stretch-active",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\micki\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-seating",
   "metadata": {},
   "source": [
    "* Shuffle the data\n",
    "* Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modular-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-carolina",
   "metadata": {},
   "source": [
    "Check the image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alleged-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train[444].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-twenty",
   "metadata": {},
   "source": [
    "Visualize one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "positive-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "animated-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-filing",
   "metadata": {},
   "source": [
    "Instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genetic-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[444]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-education",
   "metadata": {},
   "source": [
    "Convert to float and scale the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "familiar-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-smith",
   "metadata": {},
   "source": [
    "Build a CNN using Keras Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "understanding-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\micki\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\micki\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        2432      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 32)          25632     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 3, 3, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               147968    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181162 (707.66 KB)\n",
      "Trainable params: 181162 (707.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-portable",
   "metadata": {},
   "source": [
    "* Use batch size of 32\n",
    "* Initiate RMSprop optimizer\n",
    "* Train the model using RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "removed-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3878 - accuracy: 0.5407 - val_loss: 1.5179 - val_accuracy: 0.5543\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3885 - accuracy: 0.5378 - val_loss: 1.5411 - val_accuracy: 0.4767\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3942 - accuracy: 0.5367 - val_loss: 1.5981 - val_accuracy: 0.4687\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4003 - accuracy: 0.5355 - val_loss: 1.2433 - val_accuracy: 0.5799\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4116 - accuracy: 0.5281 - val_loss: 1.3871 - val_accuracy: 0.5315\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_1 = model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=5,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-lambda",
   "metadata": {},
   "source": [
    "#### Supplementary Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353052ad",
   "metadata": {},
   "source": [
    "> Achieve at least 90% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-theater",
   "metadata": {},
   "source": [
    "* Build a more complicated model with the following pattern:\n",
    "Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "\n",
    "* Use strides of 1 for all convolutional layers.\n",
    "\n",
    "* Write the number of parameters of your model  and compare it to the previous model\n",
    "\n",
    "* Train it for 5 epochs. Commpare the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
    "\n",
    "* Use different structures and run times, and see how accurate your model can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f45fee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 32, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2186282 (8.34 MB)\n",
      "Trainable params: 2186282 (8.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(filters=32, \n",
    "                   kernel_size=(5,5),\n",
    "                   strides=(1,1),\n",
    "                   padding='same',\n",
    "                   activation='relu',\n",
    "                   input_shape=x_train.shape[1:]))\n",
    "model_2.add(Conv2D(32, (5,5), strides=(1,1), padding='same',\n",
    "                   activation='relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.2))\n",
    "\n",
    "model_2.add(Conv2D(filters=64, \n",
    "                   kernel_size=(3,3),\n",
    "                   strides=(1,1),\n",
    "                   padding='same',\n",
    "                   activation='relu'))\n",
    "model_2.add(Conv2D(64, (3,3), strides=(1,1), padding='same',\n",
    "                   activation='relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17184663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 43s 54ms/step - loss: 0.7228 - accuracy: 0.7497 - val_loss: 0.7813 - val_accuracy: 0.7277\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.6799 - accuracy: 0.7633 - val_loss: 0.8569 - val_accuracy: 0.7101\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.6617 - accuracy: 0.7726 - val_loss: 0.7765 - val_accuracy: 0.7530\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 40s 52ms/step - loss: 0.6392 - accuracy: 0.7794 - val_loss: 0.7269 - val_accuracy: 0.7549\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 42s 53ms/step - loss: 0.6171 - accuracy: 0.7901 - val_loss: 0.8479 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "\n",
    "\n",
    "model_2.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "                        x_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=5,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2c9e9",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306917ab",
   "metadata": {},
   "source": [
    "> 1. Comparison of Model 1 and Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25cb482c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.387760</td>\n",
       "      <td>0.54072</td>\n",
       "      <td>1.517874</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.388537</td>\n",
       "      <td>0.53782</td>\n",
       "      <td>1.541093</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.394169</td>\n",
       "      <td>0.53668</td>\n",
       "      <td>1.598086</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.400250</td>\n",
       "      <td>0.53554</td>\n",
       "      <td>1.243251</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.411625</td>\n",
       "      <td>0.52814</td>\n",
       "      <td>1.387094</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.722786</td>\n",
       "      <td>0.74968</td>\n",
       "      <td>0.781272</td>\n",
       "      <td>0.7277</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.679914</td>\n",
       "      <td>0.76326</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.661703</td>\n",
       "      <td>0.77256</td>\n",
       "      <td>0.776493</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.639215</td>\n",
       "      <td>0.77944</td>\n",
       "      <td>0.726874</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.617101</td>\n",
       "      <td>0.79012</td>\n",
       "      <td>0.847906</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy    model  epoch\n",
       "0  1.387760   0.54072  1.517874        0.5543  Model 1      1\n",
       "1  1.388537   0.53782  1.541093        0.4767  Model 1      2\n",
       "2  1.394169   0.53668  1.598086        0.4687  Model 1      3\n",
       "3  1.400250   0.53554  1.243251        0.5799  Model 1      4\n",
       "4  1.411625   0.52814  1.387094        0.5315  Model 1      5\n",
       "5  0.722786   0.74968  0.781272        0.7277  Model 2      1\n",
       "6  0.679914   0.76326  0.856932        0.7101  Model 2      2\n",
       "7  0.661703   0.77256  0.776493        0.7530  Model 2      3\n",
       "8  0.639215   0.77944  0.726874        0.7549  Model 2      4\n",
       "9  0.617101   0.79012  0.847906        0.7370  Model 2      5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_model1 = pd.DataFrame(history_1.history)\n",
    "df_model1['model'] = 'Model 1'\n",
    "df_model1['epoch'] = df_model1.index + 1\n",
    "\n",
    "df_model2 = pd.DataFrame(history_2.history)\n",
    "df_model2['model'] = \"Model 2\"\n",
    "df_model2['epoch'] = df_model2.index + 1\n",
    "\n",
    "df1_df2 = pd.concat([df_model1, df_model2], ignore_index=True)\n",
    "\n",
    "df1_df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e83f7",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "> Model 1's accuracy peaked during the fourth epoch at ~58%, with high (1.24) loss. In contrast, Model 2 demonstrates stronger generalization, reaching higher accuracy (75.49%) with relatively lower loss(~0.73), which indicates both correctness and confidence in predictions.Model 2 is clearly outperforming Model 1, both in terms of accuracy and confidence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5af99",
   "metadata": {},
   "source": [
    "> 2. Achieve at least **90% accuracy** for both training and testing validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bddbcc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 32, 32, 64)        4864      \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 32, 64)        102464    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 16, 16, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 8, 8, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4528714 (17.28 MB)\n",
      "Trainable params: 4528714 (17.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "improve = Sequential()\n",
    "\n",
    "improve.add(Conv2D(filters=64, \n",
    "                   kernel_size=(5,5),\n",
    "                   strides=(1,1),\n",
    "                   padding='same',\n",
    "                   activation='relu',\n",
    "                   input_shape=x_train.shape[1:]))\n",
    "improve.add(Conv2D(64, (5,5), strides=(1,1), padding='same',\n",
    "                   activation='relu'))\n",
    "improve.add(MaxPooling2D(pool_size=(2,2)))\n",
    "improve.add(Dropout(0.2))\n",
    "\n",
    "improve.add(Conv2D(filters=128, \n",
    "                   kernel_size=(3,3),\n",
    "                   strides=(1,1),\n",
    "                   padding='same',\n",
    "                   activation='relu'))\n",
    "improve.add(Conv2D(128, (3,3), strides=(1,1), padding='same',\n",
    "                   activation='relu'))\n",
    "improve.add(MaxPooling2D(pool_size=(2,2)))\n",
    "improve.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "improve.add(Flatten())\n",
    "improve.add(Dense(512, activation='relu'))\n",
    "improve.add(Dropout(0.5))\n",
    "improve.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "improve.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f75831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.9201 - accuracy: 0.6807 - val_loss: 0.8872 - val_accuracy: 0.6961 - lr: 5.0000e-04\n",
      "Epoch 2/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.8180 - accuracy: 0.7199 - val_loss: 0.8884 - val_accuracy: 0.7019 - lr: 5.0000e-04\n",
      "Epoch 3/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.7754 - accuracy: 0.7388 - val_loss: 0.8101 - val_accuracy: 0.7270 - lr: 5.0000e-04\n",
      "Epoch 4/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.7536 - accuracy: 0.7490 - val_loss: 0.7758 - val_accuracy: 0.7368 - lr: 5.0000e-04\n",
      "Epoch 5/300\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.7475 - accuracy: 0.7521 - val_loss: 0.7535 - val_accuracy: 0.7659 - lr: 5.0000e-04\n",
      "Epoch 6/300\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.7354 - accuracy: 0.7585 - val_loss: 0.8702 - val_accuracy: 0.7394 - lr: 5.0000e-04\n",
      "Epoch 7/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.7328 - accuracy: 0.7627 - val_loss: 0.8408 - val_accuracy: 0.7339 - lr: 5.0000e-04\n",
      "Epoch 8/300\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.7266 - accuracy: 0.7635 - val_loss: 0.7557 - val_accuracy: 0.7659 - lr: 5.0000e-04\n",
      "Epoch 9/300\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.7335 - accuracy: 0.7631 - val_loss: 0.7240 - val_accuracy: 0.7701 - lr: 5.0000e-04\n",
      "Epoch 10/300\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 0.7293 - accuracy: 0.7645 - val_loss: 0.8581 - val_accuracy: 0.7503 - lr: 5.0000e-04\n",
      "Epoch 11/300\n",
      "1563/1563 [==============================] - 148s 95ms/step - loss: 0.7424 - accuracy: 0.7617 - val_loss: 0.7534 - val_accuracy: 0.7566 - lr: 5.0000e-04\n",
      "Epoch 12/300\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.7352 - accuracy: 0.7677 - val_loss: 0.8957 - val_accuracy: 0.7261 - lr: 5.0000e-04\n",
      "Epoch 13/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.7416 - accuracy: 0.7635 - val_loss: 0.7950 - val_accuracy: 0.7632 - lr: 5.0000e-04\n",
      "Epoch 14/300\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.7599 - accuracy: 0.7614 - val_loss: 0.7320 - val_accuracy: 0.7652 - lr: 5.0000e-04\n",
      "Epoch 15/300\n",
      "1563/1563 [==============================] - 141s 90ms/step - loss: 0.5974 - accuracy: 0.8100 - val_loss: 0.6725 - val_accuracy: 0.7805 - lr: 2.5000e-04\n",
      "Epoch 16/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5752 - accuracy: 0.8155 - val_loss: 0.6794 - val_accuracy: 0.7890 - lr: 2.5000e-04\n",
      "Epoch 17/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.5639 - accuracy: 0.8196 - val_loss: 0.6784 - val_accuracy: 0.7892 - lr: 2.5000e-04\n",
      "Epoch 18/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.5727 - accuracy: 0.8189 - val_loss: 0.7328 - val_accuracy: 0.7720 - lr: 2.5000e-04\n",
      "Epoch 19/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.5777 - accuracy: 0.8190 - val_loss: 0.6716 - val_accuracy: 0.7981 - lr: 2.5000e-04\n",
      "Epoch 20/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.5741 - accuracy: 0.8187 - val_loss: 0.6964 - val_accuracy: 0.7800 - lr: 2.5000e-04\n",
      "Epoch 21/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.5778 - accuracy: 0.8195 - val_loss: 0.7308 - val_accuracy: 0.7860 - lr: 2.5000e-04\n",
      "Epoch 22/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.5967 - accuracy: 0.8123 - val_loss: 0.6900 - val_accuracy: 0.7850 - lr: 2.5000e-04\n",
      "Epoch 23/300\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.5987 - accuracy: 0.8128 - val_loss: 0.7428 - val_accuracy: 0.7814 - lr: 2.5000e-04\n",
      "Epoch 24/300\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.6103 - accuracy: 0.8112 - val_loss: 0.6789 - val_accuracy: 0.7940 - lr: 2.5000e-04\n",
      "Epoch 25/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4915 - accuracy: 0.8418 - val_loss: 0.6345 - val_accuracy: 0.8044 - lr: 1.2500e-04\n",
      "Epoch 26/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4792 - accuracy: 0.8480 - val_loss: 0.6479 - val_accuracy: 0.8008 - lr: 1.2500e-04\n",
      "Epoch 27/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4812 - accuracy: 0.8487 - val_loss: 0.6851 - val_accuracy: 0.7858 - lr: 1.2500e-04\n",
      "Epoch 28/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4814 - accuracy: 0.8476 - val_loss: 0.7346 - val_accuracy: 0.7901 - lr: 1.2500e-04\n",
      "Epoch 29/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4931 - accuracy: 0.8442 - val_loss: 0.6611 - val_accuracy: 0.7971 - lr: 1.2500e-04\n",
      "Epoch 30/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4880 - accuracy: 0.8457 - val_loss: 0.6553 - val_accuracy: 0.8034 - lr: 1.2500e-04\n",
      "Epoch 31/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4201 - accuracy: 0.8656 - val_loss: 0.6511 - val_accuracy: 0.8035 - lr: 6.2500e-05\n",
      "Epoch 32/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4113 - accuracy: 0.8681 - val_loss: 0.6247 - val_accuracy: 0.8117 - lr: 6.2500e-05\n",
      "Epoch 33/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4130 - accuracy: 0.8679 - val_loss: 0.6275 - val_accuracy: 0.8109 - lr: 6.2500e-05\n",
      "Epoch 34/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4112 - accuracy: 0.8666 - val_loss: 0.6174 - val_accuracy: 0.8128 - lr: 6.2500e-05\n",
      "Epoch 35/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4092 - accuracy: 0.8686 - val_loss: 0.6281 - val_accuracy: 0.8125 - lr: 6.2500e-05\n",
      "Epoch 36/300\n",
      "1563/1563 [==============================] - 132s 84ms/step - loss: 0.4016 - accuracy: 0.8709 - val_loss: 0.6222 - val_accuracy: 0.8101 - lr: 6.2500e-05\n",
      "Epoch 37/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4096 - accuracy: 0.8689 - val_loss: 0.6464 - val_accuracy: 0.8081 - lr: 6.2500e-05\n",
      "Epoch 38/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4047 - accuracy: 0.8704 - val_loss: 0.6112 - val_accuracy: 0.8163 - lr: 6.2500e-05\n",
      "Epoch 39/300\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4002 - accuracy: 0.8721 - val_loss: 0.6131 - val_accuracy: 0.8154 - lr: 6.2500e-05\n",
      "Epoch 40/300\n",
      "1563/1563 [==============================] - 140s 89ms/step - loss: 0.4055 - accuracy: 0.8724 - val_loss: 0.6570 - val_accuracy: 0.8143 - lr: 6.2500e-05\n",
      "Epoch 41/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.4001 - accuracy: 0.8733 - val_loss: 0.6532 - val_accuracy: 0.8065 - lr: 6.2500e-05\n",
      "Epoch 42/300\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.3983 - accuracy: 0.8722 - val_loss: 0.6116 - val_accuracy: 0.8140 - lr: 6.2500e-05\n",
      "Epoch 43/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3943 - accuracy: 0.8721 - val_loss: 0.6193 - val_accuracy: 0.8153 - lr: 6.2500e-05\n",
      "Epoch 44/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3604 - accuracy: 0.8854 - val_loss: 0.6192 - val_accuracy: 0.8163 - lr: 3.1250e-05\n",
      "Epoch 45/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3592 - accuracy: 0.8840 - val_loss: 0.6084 - val_accuracy: 0.8213 - lr: 3.1250e-05\n",
      "Epoch 46/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.3560 - accuracy: 0.8861 - val_loss: 0.6174 - val_accuracy: 0.8138 - lr: 3.1250e-05\n",
      "Epoch 47/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3568 - accuracy: 0.8860 - val_loss: 0.6074 - val_accuracy: 0.8198 - lr: 3.1250e-05\n",
      "Epoch 48/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3551 - accuracy: 0.8867 - val_loss: 0.6145 - val_accuracy: 0.8182 - lr: 3.1250e-05\n",
      "Epoch 49/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.3481 - accuracy: 0.8865 - val_loss: 0.6107 - val_accuracy: 0.8202 - lr: 3.1250e-05\n",
      "Epoch 50/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.3522 - accuracy: 0.8858 - val_loss: 0.6083 - val_accuracy: 0.8168 - lr: 3.1250e-05\n",
      "Epoch 51/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.3513 - accuracy: 0.8870 - val_loss: 0.6100 - val_accuracy: 0.8203 - lr: 3.1250e-05\n",
      "Epoch 52/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.3568 - accuracy: 0.8858 - val_loss: 0.6056 - val_accuracy: 0.8203 - lr: 3.1250e-05\n",
      "Epoch 53/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.3484 - accuracy: 0.8871 - val_loss: 0.6207 - val_accuracy: 0.8143 - lr: 3.1250e-05\n",
      "Epoch 54/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.3465 - accuracy: 0.8889 - val_loss: 0.6526 - val_accuracy: 0.8061 - lr: 3.1250e-05\n",
      "Epoch 55/300\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.3541 - accuracy: 0.8874 - val_loss: 0.6205 - val_accuracy: 0.8157 - lr: 3.1250e-05\n",
      "Epoch 56/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.3433 - accuracy: 0.8914 - val_loss: 0.6232 - val_accuracy: 0.8156 - lr: 3.1250e-05\n",
      "Epoch 57/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.3541 - accuracy: 0.8882 - val_loss: 0.6138 - val_accuracy: 0.8178 - lr: 3.1250e-05\n",
      "Epoch 58/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3287 - accuracy: 0.8944 - val_loss: 0.5962 - val_accuracy: 0.8209 - lr: 1.5625e-05\n",
      "Epoch 59/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3360 - accuracy: 0.8919 - val_loss: 0.6107 - val_accuracy: 0.8175 - lr: 1.5625e-05\n",
      "Epoch 60/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.3298 - accuracy: 0.8939 - val_loss: 0.6050 - val_accuracy: 0.8226 - lr: 1.5625e-05\n",
      "Epoch 61/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3227 - accuracy: 0.8963 - val_loss: 0.6072 - val_accuracy: 0.8201 - lr: 1.5625e-05\n",
      "Epoch 62/300\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 0.3258 - accuracy: 0.8941 - val_loss: 0.6029 - val_accuracy: 0.8190 - lr: 1.5625e-05\n",
      "Epoch 63/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3256 - accuracy: 0.8952 - val_loss: 0.6181 - val_accuracy: 0.8178 - lr: 1.5625e-05\n",
      "Epoch 64/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3216 - accuracy: 0.8957 - val_loss: 0.6026 - val_accuracy: 0.8203 - lr: 7.8125e-06\n",
      "Epoch 65/300\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.3175 - accuracy: 0.8970 - val_loss: 0.6115 - val_accuracy: 0.8208 - lr: 7.8125e-06\n",
      "Epoch 66/300\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.3128 - accuracy: 0.8977 - val_loss: 0.6050 - val_accuracy: 0.8210 - lr: 7.8125e-06\n",
      "Epoch 67/300\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.3107 - accuracy: 0.9000 - val_loss: 0.6130 - val_accuracy: 0.8168 - lr: 7.8125e-06\n",
      "Epoch 68/300\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.3178 - accuracy: 0.8976 - val_loss: 0.6166 - val_accuracy: 0.8170 - lr: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "\n",
    "improve.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_3 = improve.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[early_stop, lr_reduce]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05970e01",
   "metadata": {},
   "source": [
    "> I tried a different approach under this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67c1493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, Activation,\n",
    "                                     Dropout, MaxPooling2D, Flatten, Dense)\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6125193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model_3.add(Conv2D(64, (1,1), padding=\"same\",\n",
    "                   input_shape=(32, 32, 3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv2D(64, (5,5), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Dropout(0.25))\n",
    "model_3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Block 2\n",
    "model_3.add(Conv2D(128, (1,1), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv2D(128, (5,5), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "# Block 3\n",
    "model_3.add(Conv2D(256, (1,1), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv2D(256, (5,5), padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25dc67f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 32, 32, 64)        256       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 64)        256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 16, 16, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 16, 16, 128)       8320      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 16, 16, 128)       409728    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 16, 16, 256)       33024     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 16, 16, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 16, 16, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 16, 16, 256)       1638656   \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 16, 16, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                655370    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3627786 (13.84 MB)\n",
      "Trainable params: 3625098 (13.83 MB)\n",
      "Non-trainable params: 2688 (10.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer=Adam(),\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe0350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "391/391 [==============================] - 573s 1s/step - loss: 2.3736 - accuracy: 0.3593 - val_loss: 2.2953 - val_accuracy: 0.2732\n",
      "Epoch 2/700\n",
      "391/391 [==============================] - 570s 1s/step - loss: 1.3143 - accuracy: 0.5363 - val_loss: 1.2947 - val_accuracy: 0.5379\n",
      "Epoch 3/700\n",
      "391/391 [==============================] - 572s 1s/step - loss: 1.0404 - accuracy: 0.6327 - val_loss: 1.3871 - val_accuracy: 0.5480\n",
      "Epoch 4/700\n",
      "391/391 [==============================] - 575s 1s/step - loss: 0.8517 - accuracy: 0.7010 - val_loss: 1.0467 - val_accuracy: 0.6401\n",
      "Epoch 5/700\n",
      "391/391 [==============================] - 578s 1s/step - loss: 0.7143 - accuracy: 0.7523 - val_loss: 0.8749 - val_accuracy: 0.6947\n",
      "Epoch 6/700\n",
      "391/391 [==============================] - 579s 1s/step - loss: 0.6044 - accuracy: 0.7898 - val_loss: 0.7918 - val_accuracy: 0.7344\n",
      "Epoch 7/700\n",
      "391/391 [==============================] - 595s 2s/step - loss: 0.5202 - accuracy: 0.8199 - val_loss: 0.7520 - val_accuracy: 0.7519\n",
      "Epoch 8/700\n",
      "391/391 [==============================] - 576s 1s/step - loss: 0.4522 - accuracy: 0.8446 - val_loss: 0.6202 - val_accuracy: 0.7864\n",
      "Epoch 9/700\n",
      "391/391 [==============================] - 576s 1s/step - loss: 0.4325 - accuracy: 0.8507 - val_loss: 1.3090 - val_accuracy: 0.5452\n",
      "Epoch 10/700\n",
      "391/391 [==============================] - 575s 1s/step - loss: 0.3779 - accuracy: 0.8675 - val_loss: 0.6763 - val_accuracy: 0.7831\n",
      "Epoch 11/700\n",
      "391/391 [==============================] - 577s 1s/step - loss: 0.3025 - accuracy: 0.8954 - val_loss: 0.6276 - val_accuracy: 0.7956\n",
      "Epoch 12/700\n",
      "391/391 [==============================] - 578s 1s/step - loss: 0.2541 - accuracy: 0.9111 - val_loss: 0.6080 - val_accuracy: 0.8060\n",
      "Epoch 13/700\n",
      "391/391 [==============================] - 578s 1s/step - loss: 0.2183 - accuracy: 0.9238 - val_loss: 0.7117 - val_accuracy: 0.7901\n",
      "Epoch 14/700\n",
      "391/391 [==============================] - 577s 1s/step - loss: 0.1801 - accuracy: 0.9355 - val_loss: 0.7037 - val_accuracy: 0.7972\n",
      "Epoch 15/700\n",
      "391/391 [==============================] - 588s 2s/step - loss: 0.1540 - accuracy: 0.9456 - val_loss: 0.6739 - val_accuracy: 0.8162\n",
      "Epoch 16/700\n",
      "391/391 [==============================] - 583s 1s/step - loss: 0.1336 - accuracy: 0.9528 - val_loss: 0.7423 - val_accuracy: 0.8086\n",
      "Epoch 17/700\n",
      "391/391 [==============================] - 592s 2s/step - loss: 0.1193 - accuracy: 0.9579 - val_loss: 0.9518 - val_accuracy: 0.7701\n",
      "Epoch 18/700\n",
      "391/391 [==============================] - 586s 1s/step - loss: 0.1075 - accuracy: 0.9615 - val_loss: 0.7589 - val_accuracy: 0.8088\n",
      "Epoch 19/700\n",
      "391/391 [==============================] - 585s 1s/step - loss: 0.0907 - accuracy: 0.9687 - val_loss: 0.9104 - val_accuracy: 0.7933\n",
      "Epoch 20/700\n",
      "391/391 [==============================] - 598s 2s/step - loss: 0.0852 - accuracy: 0.9694 - val_loss: 0.8292 - val_accuracy: 0.8056\n",
      "Epoch 21/700\n",
      "391/391 [==============================] - 602s 2s/step - loss: 0.0840 - accuracy: 0.9703 - val_loss: 0.8582 - val_accuracy: 0.7976\n",
      "Epoch 22/700\n",
      "391/391 [==============================] - 594s 2s/step - loss: 0.0765 - accuracy: 0.9739 - val_loss: 0.8600 - val_accuracy: 0.8059\n",
      "Epoch 23/700\n",
      "391/391 [==============================] - 588s 2s/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 0.7774 - val_accuracy: 0.8191\n",
      "Epoch 24/700\n",
      "391/391 [==============================] - 579s 1s/step - loss: 0.0593 - accuracy: 0.9795 - val_loss: 0.8338 - val_accuracy: 0.8178\n",
      "Epoch 25/700\n",
      "391/391 [==============================] - 587s 2s/step - loss: 0.0604 - accuracy: 0.9796 - val_loss: 0.8856 - val_accuracy: 0.8100\n",
      "Epoch 26/700\n",
      "391/391 [==============================] - 583s 1s/step - loss: 0.0582 - accuracy: 0.9801 - val_loss: 0.8410 - val_accuracy: 0.8174\n",
      "Epoch 27/700\n",
      "391/391 [==============================] - 580s 1s/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.9312 - val_accuracy: 0.8049\n",
      "Epoch 28/700\n",
      "391/391 [==============================] - 598s 2s/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.8578 - val_accuracy: 0.8192\n",
      "Epoch 29/700\n",
      "391/391 [==============================] - 595s 2s/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 1.1442 - val_accuracy: 0.7955\n",
      "Epoch 30/700\n",
      "391/391 [==============================] - 605s 2s/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.8673 - val_accuracy: 0.8151\n",
      "Epoch 31/700\n",
      "391/391 [==============================] - 589s 2s/step - loss: 0.0421 - accuracy: 0.9852 - val_loss: 0.8994 - val_accuracy: 0.8193\n",
      "Epoch 32/700\n",
      "391/391 [==============================] - 590s 2s/step - loss: 0.0404 - accuracy: 0.9856 - val_loss: 1.0750 - val_accuracy: 0.7885\n",
      "Epoch 33/700\n",
      "391/391 [==============================] - 578s 1s/step - loss: 0.0415 - accuracy: 0.9853 - val_loss: 0.9560 - val_accuracy: 0.8164\n",
      "Epoch 34/700\n",
      "391/391 [==============================] - 567s 1s/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 1.0540 - val_accuracy: 0.8024\n",
      "Epoch 35/700\n",
      "391/391 [==============================] - 573s 1s/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 0.9089 - val_accuracy: 0.8284\n",
      "Epoch 36/700\n",
      "391/391 [==============================] - 572s 1s/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.9219 - val_accuracy: 0.8271\n",
      "Epoch 37/700\n",
      "391/391 [==============================] - 571s 1s/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 1.0674 - val_accuracy: 0.8122\n",
      "Epoch 38/700\n",
      "391/391 [==============================] - 568s 1s/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.9165 - val_accuracy: 0.8295\n",
      "Epoch 39/700\n",
      "391/391 [==============================] - 573s 1s/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 0.9142 - val_accuracy: 0.8312\n",
      "Epoch 40/700\n",
      "391/391 [==============================] - 581s 1s/step - loss: 0.0343 - accuracy: 0.9880 - val_loss: 0.9063 - val_accuracy: 0.8275\n",
      "Epoch 41/700\n",
      "391/391 [==============================] - 559s 1s/step - loss: 0.0324 - accuracy: 0.9889 - val_loss: 0.9025 - val_accuracy: 0.8311\n",
      "Epoch 42/700\n",
      "391/391 [==============================] - 549s 1s/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.9134 - val_accuracy: 0.8315\n",
      "Epoch 43/700\n",
      "391/391 [==============================] - 548s 1s/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.9766 - val_accuracy: 0.8308\n",
      "Epoch 44/700\n",
      "391/391 [==============================] - 546s 1s/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.9254 - val_accuracy: 0.8273\n",
      "Epoch 45/700\n",
      "391/391 [==============================] - 546s 1s/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.9765 - val_accuracy: 0.8258\n",
      "Epoch 46/700\n",
      "391/391 [==============================] - 547s 1s/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.9057 - val_accuracy: 0.8305\n",
      "Epoch 47/700\n",
      "391/391 [==============================] - 547s 1s/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 1.0927 - val_accuracy: 0.8155\n",
      "Epoch 48/700\n",
      "391/391 [==============================] - 561s 1s/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.9583 - val_accuracy: 0.8282\n",
      "Epoch 49/700\n",
      "391/391 [==============================] - 565s 1s/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.9269 - val_accuracy: 0.8272\n",
      "Epoch 50/700\n",
      "391/391 [==============================] - 562s 1s/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 1.0800 - val_accuracy: 0.8085\n",
      "Epoch 51/700\n",
      "391/391 [==============================] - 562s 1s/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.9591 - val_accuracy: 0.8254\n",
      "Epoch 52/700\n",
      "391/391 [==============================] - 565s 1s/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 1.1635 - val_accuracy: 0.8110\n",
      "Epoch 53/700\n",
      "387/391 [============================>.] - ETA: 5s - loss: 0.0218 - accuracy: 0.9928"
     ]
    }
   ],
   "source": [
    "batch_size3 = 128\n",
    "\n",
    "history_4 = model_3.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=700,\n",
    "    batch_size=batch_size3,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-still",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-jackson",
   "metadata": {},
   "source": [
    "> In this activity, convolutional neural networks (CNNs) were built and trained using the CIFAR-10 dataset to observe how different architectural choices affect model performance. The results showed that changing kernel sizes from smaller, fine-grained filters (such as 33) to larger ones (such as 55) helped the model capture both small details and broader patterns in the images. Increasing the number of convolutional filters also improved performance, as the model was able to learn more distinguishing features, which helped with generalization.\n",
    "\n",
    "> Moreover, delaying downsampling by using stride-1 convolutions allowed the model to preserve information in the early layers. Meanwhile, ultimately skipping downsampling led to higher accuracy, although it came at the cost of longer training time and increased computational load. Batch normalization and dropout further helped stabilize training and reduce overfitting by keeping activations well-scaled and preventing the model from relying too heavily on specific neurons. Lastly, reducing the size of the dense layer from 512 to 256 to 10 neurons lowered the overall number of parameters, which helped improve generalization while still maintaining competitive classification accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
